{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of IA_backgammon.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSRROOAi60ZU",
        "colab_type": "code",
        "outputId": "9a8c0423-6663-4597-8d71-282de39db9ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!pip3 install pygame"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/ede6428359f913ed9cd1643dd5533aefeb5a2699cc95bea089de50ead586/pygame-1.9.6-cp36-cp36m-manylinux1_x86_64.whl (11.4MB)\n",
            "\u001b[K     |████████████████████████████████| 11.4MB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-1.9.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB2xqAq6bHzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBCazY8uruNO",
        "colab_type": "code",
        "outputId": "0d36a859-715f-4bbe-fd65-3fcb3def5863",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = \"cpu\" #torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using gpu: True \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHD2s-cM7YDT",
        "colab_type": "text"
      },
      "source": [
        "Data description : \n",
        " One array of size 30\n",
        " - the result of the remaing dices action : four slots\n",
        "   The numbers go from 0 to 6 : 0 if already played it\n",
        "  \n",
        " - the board state composed of :\n",
        "      - 24 first digit from -9 to +9 for black and white pins on the arrows\n",
        "      - 2 folowing for number of pins that finished : white and black\n",
        "      - 2 last for number of pins in prison : white and black\n",
        "\n",
        "The output represents the space of possible actions.\n",
        "We need to map every possible action to an integer.\n",
        "We have 25 slots from where a pin can move with all 6 possible dice rolls, which leads to 150 possible actions.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_lns7Ir9P1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size_ = 32\n",
        "output_size_ = 175\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTohNxApKPmu",
        "colab_type": "text"
      },
      "source": [
        "This function take as an argument an integer from 0 to 149 and returns a tuple (i,j,k) where : \n",
        "  - i = arrow id\n",
        "  - value of dice used\n",
        "  - -1, 0 or 1 if the pin eats another one, nothing particular, the pin goes out\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmoIwxarFE9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_action_space():\n",
        "  table = np.array([[[0]*3]*7]*25)\n",
        "  for k in range(25):\n",
        "    for l in range(7):\n",
        "      table[k][l][0] = k\n",
        "      table[k][l][1] = l\n",
        "      if k+l>24:\n",
        "        table[k][l][2] = 1\n",
        "\n",
        "action_space = compute_action_space()\n",
        "\n",
        "def get_action(indx, eats):\n",
        "  pos, roll, result = action_space[indx//6][indx%6]\n",
        "  if eats :\n",
        "    result = -1\n",
        "  return (pos, roll, result)\n",
        "\n",
        "def get_idx(action):\n",
        "  pos, roll, _ = action\n",
        "  return pos*6+roll\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljo52z4yPlU4",
        "colab_type": "text"
      },
      "source": [
        "Let's create a functions to help later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9-zpTSTycAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref_score = 24*15\n",
        "\n",
        "def get_score(board):\n",
        "  result = 0\n",
        "  result+= (board[24]-board[25])*24\n",
        "  for k,pins in enumerate(board[:24]) :\n",
        "    if pins > 0 :\n",
        "      if pins > 1 :\n",
        "        result += (pins*((k//6)+1)*6+2)\n",
        "      else :\n",
        "        result+= ((k//6)+1)\n",
        "  result/=ref_score\n",
        "  return result\n",
        "    \n",
        "\n",
        "def max_value(resulting_states):\n",
        "  s = resulting_states[0]\n",
        "  m = get_score(s.board[:28])\n",
        "  i=0\n",
        "  for k,res in enumerate(resulting_states[1:]) :\n",
        "    sc = get_score(res.board[:28])\n",
        "    if sc > m :\n",
        "      m = sc\n",
        "      s = res\n",
        "      i=k\n",
        "  if s.board[24]==15:\n",
        "    m+=1\n",
        "  return m,s,i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijOkLT_xEqsj",
        "colab_type": "text"
      },
      "source": [
        "Now we can use gym and write the data generation loop.\n",
        "\n",
        "First lets load the necessary files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7P0uLLrKU_O",
        "colab_type": "text"
      },
      "source": [
        "We will need a structure to store the data we generate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT3BS3xKKVrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class data_manager():\n",
        "  def __init__(self, df_size):\n",
        "    self.df = []\n",
        "    self.df_size_ = df_size\n",
        "\n",
        "  def reset(self):\n",
        "    self.df = []\n",
        "\n",
        "  def is_full(self):\n",
        "    return len(self.df) == self.df_size_\n",
        "\n",
        "  def add(self, plays):\n",
        "    to_add = plays.copy()\n",
        "    if self.is_full():\n",
        "      print(\"already full\")\n",
        "    else :\n",
        "      for play in to_add :\n",
        "        self.df.append(play)\n",
        "\n",
        "  def get_df(self):\n",
        "    return self.df\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY7YUxzTE1oO",
        "colab_type": "code",
        "outputId": "8aa34432-b32d-406a-8345-fbd5ce6b77b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!git clone https://github.com/jcGourcuff/BackGammon.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BackGammon'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 84 (delta 36), reused 82 (delta 34), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (84/84), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibtUQm_eKTlJ",
        "colab_type": "code",
        "outputId": "1f6158fd-d59d-454f-b94e-04ff751f91b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd BackGammon/"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/BackGammon\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b32pn5WNKcQq",
        "colab_type": "code",
        "outputId": "f3601cd4-5af0-4c31-c43e-32dba2524c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from BackGammon.envs.backgammon_env  import BackgammonEnv\n",
        "from BackGammon.envs.backgammon import State, WhiteAgent"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 1.9.6\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSnCNCjVS8xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_episodes = 10\n",
        "Backenv = BackgammonEnv()\n",
        "max_steps = 1000\n",
        "epsilon = 1.\n",
        "epsilon_min = .01\n",
        "epsilon_decay = .75"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH2rZzGFKgqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_roll(dice_roll):\n",
        "  roll = dice_roll\n",
        "  if roll[0]!=roll[1]:\n",
        "    return roll+ [0,0]\n",
        "  else : \n",
        "    return roll + roll\n",
        " \n",
        "\n",
        "def next_step(agent, state, dice, choice = 'greed'):\n",
        "  \"\"\"\n",
        "  From a board state and a roll, return the best outcome State, its score, the move chosen and its corresponding array.\n",
        "  \"\"\"\n",
        "  state = state\n",
        "  possible_moves = agent.possible_moves(dice)\n",
        "  move, next_state, reward = None, None, 0\n",
        "\n",
        "  if choice == 'greed' :\n",
        "      possible_next_states = [State(state, move = m) for m in possible_moves]\n",
        "      score, next_state, idx = max_value(possible_next_states)\n",
        "      next_state = possible_next_states[idx]\n",
        "      move = possible_moves[idx]\n",
        "\n",
        "  else :\n",
        "      move = possible_moves[np.random.randint(len(possible_moves))]\n",
        "      next_state = State(previous_state = state, move = move)\n",
        "      \n",
        "      \n",
        "  if next_state.board[24]==15 :\n",
        "          reward = 1\n",
        "  Q_value = get_score(next_state.board[:28])-get_score(state.board[:28])\n",
        "\n",
        "  return next_state, Q_value, reward, move, get_idx(move)\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "def generate_data(episodes, env, max_steps, epsilon, verbose = False):\n",
        "  eps = epsilon\n",
        "  data = data_manager(episodes*max_steps)\n",
        "  episode = 0\n",
        "  while episode < episodes and not data.is_full():\n",
        "      # Reset the game state, done and score before every episode/game\n",
        "      env.reset() #Gets current game state\n",
        "      done = False        #decides whether the game is over\n",
        "      mem_state = State()\n",
        "      k=0\n",
        "      if verbose : \n",
        "        print(\"start episode \"+str(episode))\n",
        "\n",
        "      while k < max_steps and not data.is_full() : \n",
        "        white_roll = [np.random.randint(1, 7), np.random.randint(1, 7)]\n",
        "        plays = []\n",
        "        action = []\n",
        "        rolls = convert_roll(white_roll)\n",
        "        rolls_input = rolls.copy()\n",
        "\n",
        "        if verbose :\n",
        "          print(\"turn {}\".format(k), end = '\\r')\n",
        "\n",
        "        for i,roll in enumerate(rolls) :\n",
        "          if roll >0 :\n",
        "            roll_for_dataset = rolls_input.copy()\n",
        "            if 0.5 > np.random.random():\n",
        "              roll_for_dataset[0], roll_for_dataset[1] = roll_for_dataset[1],roll_for_dataset[0]\n",
        "            modelInput =  roll_for_dataset + mem_state.board[:28].copy()\n",
        "            white = WhiteAgent(mem_state)\n",
        "            next_state = None\n",
        "            move = None\n",
        "            target = None\n",
        "            score = None\n",
        "\n",
        "            if np.random.uniform(0, 1) > eps:\n",
        "              next_state, Q_value, reward, move, target = next_step(white,mem_state, roll)\n",
        "            else :\n",
        "              next_state, Q_value, reward, move, target = next_step(white,mem_state, roll, choice = 'random')\n",
        "            \n",
        "            finished = (next_state.board[24]==15)|(next_state.board[25]==15)\n",
        "\n",
        "            potential = 0\n",
        "            if not finished :\n",
        "              pot_roll = np.random.randint(1, 7)\n",
        "              _, potential, _, _ = next_step(WhiteAgent(next_state), next_state, pot_roll)\n",
        "\n",
        "            else :\n",
        "              done = True\n",
        "              \n",
        "            plays.append([modelInput, move, Q_value, potential, finished, move])\n",
        "\n",
        "            action.append(move)\n",
        "            \n",
        "            mem_state = State(previous_state = mem_state, move = move)\n",
        "          \n",
        "          else:\n",
        "            break\n",
        "\n",
        "          rolls_input[i]=0\n",
        "\n",
        "        data.add(plays)\n",
        "        _, _, _, _ = env.step(action)\n",
        "\n",
        "        k+=1\n",
        "\n",
        "        if done:\n",
        "          episode +=1\n",
        "          break\n",
        "\n",
        "      # Reducing our epsilon each episode (Exploration-Exploitation trade-off)\n",
        "      #if eps >= epsilon_min:\n",
        "      #    eps *= epsilon_decay\n",
        "\n",
        "  return data\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfXqC4nkQ6k8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = generate_data(nb_episodes, Backenv, max_steps = max_steps, epsilon = epsilon)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxrBsycTJ9CX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_data.get_df()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dGp2bPDiiTe",
        "colab_type": "code",
        "outputId": "eaa288fd-8a87-4d21-e4a9-f32613fd00a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgYwX9VlQXRc",
        "colab_type": "text"
      },
      "source": [
        "Now let's create the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYG3LH-SQana",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BackgammonNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BackgammonNet, self).__init__()\n",
        "    self.input_size = 32\n",
        "    self.output_size = 175\n",
        "    self.classifier = nn.Sequential(nn.Linear(self.input_size,self.input_size),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Dropout(inplace = False),\n",
        "                                    nn.Linear(self.input_size,100),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Dropout(inplace = False),\n",
        "                                    nn.Linear(100,200),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Dropout(inplace = False),\n",
        "                                    nn.Linear(200,200),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Dropout(inplace = False),\n",
        "                                    nn.Linear(200,self.output_size))\n",
        "    \n",
        "  def forward(self,x):\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu7zXwd6UVcd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Now lets instanciate a torch-compatible dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_lxyP5TKO-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PlaysDataset(Dataset):\n",
        "\n",
        "  def __init__(self, data, transform = None):\n",
        "      self.data = data\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "\n",
        "      line = self.data[idx].copy()\n",
        "      ins = np.array(line[0])\n",
        "      target = np.array(line[1])\n",
        "      score = np.array(line[2])\n",
        "      potential = np.array(line[3])\n",
        "      finished = np.array(line[4])\n",
        "      move_tuple = np.array(line[5])\n",
        "      sample = {'ins': ins, 'target': target, 'score':score, 'potential':potential, 'finished':finished, 'move_tuple':move_tuple}\n",
        "      return sample\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onPO0vxKKxFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size_ = 10\n",
        "epochs_ = 10\n",
        "\n",
        "train_set = PlaysDataset(train_data)\n",
        "train_loader = DataLoader(train_set, batch_size = batch_size_, shuffle = True, num_workers = 6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IA5PSK6jaJk",
        "colab_type": "text"
      },
      "source": [
        "We now need to define our loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vKohUqYm8sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = 0.1\n",
        "gamma = 0.1\n",
        "\n",
        "mse_loss = nn.MSELoss().to(device)\n",
        "\n",
        "def custom_loss(,score, potential, is_win, final_move):\n",
        "  if final_move :\n",
        "     if is_win :\n",
        "       return mse_loss(1, torch.floor(potential))\n",
        "  else :\n",
        "    return mse_loss(score, )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJZdQ5N-X25Y",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Let's also choose a learning rate and an optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl7Z-iZsM2EI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = custom_loss\n",
        "learning_rate = 1e-2\n",
        "model = BackgammonNet().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "sftmx = nn.functional.log_softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GYBvyNBYcX1",
        "colab_type": "text"
      },
      "source": [
        "Let's write the training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsJzRzrsYsWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, dataloader, size, learning_rate, num_epoch, train_mode = 'learn_to_play'):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  moves = []\n",
        "\n",
        "  for epoch in range(num_epoch):\n",
        "    nb_possible = 0.0\n",
        "    for batch in dataloader :\n",
        "      \n",
        "      ins = torch.LongTensor(batch['ins']).type(torch.FloatTensor)\n",
        "      ins = ins.to(device)\n",
        "\n",
        "      targets = torch.LongTensor(torch.tensor(batch['target'])).to(device)\n",
        "\n",
        "      outs = model(ins)\n",
        "      outs = torch.FloatTensor(sftmx(outs)).to(device)\n",
        "\n",
        "      scores = torch.DoubleTensor(batch['score']).type(torch.FloatTensor).to(device)\n",
        "      \n",
        "      potentials = torch.DoubleTensor(batch['potential']).type(torch.FloatTensor).to(device)\n",
        "\n",
        "      loss = loss_fn(outs, targets, scores, potentials)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      _, preds = torch.max(outs, 1)\n",
        "\n",
        "      l = loss.data.item()\n",
        "      running_loss += l\n",
        "      moves = moves + preds.tolist() \n",
        "    epoch_loss = running_loss / size\n",
        "    print('epoch: {} Loss: {:.4f}'.format(epoch, epoch_loss))\n",
        "  return moves"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKZjAFpMRmOT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "69c281a8-37c7-47e2-908c-9f926e89e1bd"
      },
      "source": [
        "moves = train(model, optimizer, train_loader,len(train_data), learning_rate, num_epoch= epochs_ )"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 Loss: 0.4058\n",
            "epoch: 1 Loss: 0.8119\n",
            "epoch: 2 Loss: 1.2111\n",
            "epoch: 3 Loss: 1.6096\n",
            "epoch: 4 Loss: 2.0066\n",
            "epoch: 5 Loss: 2.4085\n",
            "epoch: 6 Loss: 2.8033\n",
            "epoch: 7 Loss: 3.1954\n",
            "epoch: 8 Loss: 3.5913\n",
            "epoch: 9 Loss: 3.9822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54AevSmueF8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}